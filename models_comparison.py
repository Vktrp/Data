import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import TimeSeriesSplit
import warnings
warnings.filterwarnings('ignore')

"""
COMPARAISON DE MOD√àLES ML
Compare XGBoost, Random Forest et Gradient Boosting
"""

sns.set_theme(style="whitegrid")

print("="*70)
print("üîç COMPARAISON DE MOD√àLES DE MACHINE LEARNING")
print("="*70)

# =============================================================================
# üìÇ CHARGEMENT ET PR√âPARATION
# =============================================================================

print("\nüìÇ Chargement des donn√©es...")
df = pd.read_csv("admissions_daily.csv", parse_dates=["date"])
df = df.sort_values("date").reset_index(drop=True)

print(f"‚úÖ {len(df)} jours de donn√©es")

# =============================================================================
# üîß FEATURE ENGINEERING
# =============================================================================

print("\nüîß Cr√©ation des features...")

# Features temporelles
df['jour_semaine'] = df['date'].dt.dayofweek
df['jour_mois'] = df['date'].dt.day
df['jour_annee'] = df['date'].dt.dayofyear
df['semaine_annee'] = df['date'].dt.isocalendar().week
df['mois'] = df['date'].dt.month
df['trimestre'] = df['date'].dt.quarter

# Indicateurs bool√©ens
df['is_monday'] = (df['jour_semaine'] == 0).astype(int)
df['is_tuesday'] = (df['jour_semaine'] == 1).astype(int)
df['is_friday'] = (df['jour_semaine'] == 4).astype(int)
df['is_weekend'] = (df['jour_semaine'] >= 5).astype(int)
df['is_debut_mois'] = (df['jour_mois'] <= 7).astype(int)
df['is_fin_mois'] = (df['jour_mois'] >= 24).astype(int)
df['is_event'] = df['event'].apply(lambda x: 1 if x != 'none' and pd.notnull(x) else 0)

# Saisonnalit√©
df['sin_semaine'] = np.sin(2 * np.pi * df['jour_semaine'] / 7)
df['cos_semaine'] = np.cos(2 * np.pi * df['jour_semaine'] / 7)
df['sin_mois'] = np.sin(2 * np.pi * df['jour_mois'] / 31)
df['cos_mois'] = np.cos(2 * np.pi * df['jour_mois'] / 31)
df['sin_annee'] = np.sin(2 * np.pi * df['jour_annee'] / 365)
df['cos_annee'] = np.cos(2 * np.pi * df['jour_annee'] / 365)

# Lags
for lag in [1, 2, 3, 4, 5, 6, 7, 14, 21, 28]:
    df[f'lag_{lag}'] = df['nb_admissions'].shift(lag)

# Diff√©rences
df['diff_1'] = df['nb_admissions'].diff(1)
df['diff_7'] = df['nb_admissions'].diff(7)

# Rolling statistics
windows = [3, 7, 14, 21, 30]
for window in windows:
    df[f'rolling_mean_{window}'] = df['nb_admissions'].shift(1).rolling(window=window).mean()
    df[f'rolling_std_{window}'] = df['nb_admissions'].shift(1).rolling(window=window).std()
    df[f'rolling_min_{window}'] = df['nb_admissions'].shift(1).rolling(window=window).min()
    df[f'rolling_max_{window}'] = df['nb_admissions'].shift(1).rolling(window=window).max()

# Features d√©riv√©es
df['trend'] = df['rolling_mean_7'] - df['rolling_mean_30']
df['momentum_3'] = df['nb_admissions'].shift(1) - df['nb_admissions'].shift(4)
df['ratio_to_mean_7'] = df['nb_admissions'].shift(1) / (df['rolling_mean_7'] + 1)

# Interactions
df['monday_x_lag1'] = df['is_monday'] * df['lag_1']
df['weekend_x_mean7'] = df['is_weekend'] * df['rolling_mean_7']

# Nettoyer
df = df.replace([np.inf, -np.inf], np.nan)
df = df.dropna()

print(f"‚úÖ {len(df.columns) - 3} features cr√©√©es")

# =============================================================================
# üìä SPLIT TRAIN/TEST
# =============================================================================

train_size = len(df) - 60
train = df.iloc[:train_size]
test = df.iloc[train_size:]

features = [col for col in df.columns if col not in ['date', 'nb_admissions', 'event']]
target = 'nb_admissions'

print(f"üìä Split: {len(train)} train / {len(test)} test")

# =============================================================================
# ü§ñ D√âFINITION DES MOD√àLES
# =============================================================================

models = {
    'XGBoost': {
        'model': XGBRegressor(
            n_estimators=1000,
            learning_rate=0.05,
            max_depth=6,
            min_child_weight=3,
            subsample=0.8,
            colsample_bytree=0.8,
            random_state=42,
            n_jobs=-1
        ),
        'description': 'Boosting avec gradient optimis√©',
        'color': '#E74C3C'
    },
    'Random Forest': {
        'model': RandomForestRegressor(
            n_estimators=500,
            max_depth=12,
            min_samples_split=5,
            random_state=42,
            n_jobs=-1
        ),
        'description': 'Ensemble d\'arbres de d√©cision',
        'color': '#3498DB'
    },
    'Gradient Boosting': {
        'model': GradientBoostingRegressor(
            n_estimators=500,
            learning_rate=0.05,
            max_depth=5,
            random_state=42
        ),
        'description': 'Boosting s√©quentiel',
        'color': '#27AE60'
    }
}

# =============================================================================
# üèãÔ∏è ENTRA√éNEMENT ET √âVALUATION
# =============================================================================

print("\n" + "="*70)
print("üèãÔ∏è ENTRA√éNEMENT DES MOD√àLES")
print("="*70)

results = {}

for name, config in models.items():
    print(f"\nüìç Entra√Ænement: {name}")
    print(f"   Description: {config['description']}")
    
    model = config['model']
    
    # Entra√Ænement
    model.fit(train[features], train[target])
    
    # Pr√©dictions
    preds_train = model.predict(train[features])
    preds_test = model.predict(test[features])
    
    # M√©triques sur le test
    mae = mean_absolute_error(test[target], preds_test)
    rmse = np.sqrt(mean_squared_error(test[target], preds_test))
    r2 = r2_score(test[target], preds_test)
    mape = np.mean(np.abs((test[target] - preds_test) / test[target])) * 100
    
    # M√©triques sur le train (pour d√©tecter l'overfitting)
    r2_train = r2_score(train[target], preds_train)
    
    results[name] = {
        'model': model,
        'predictions_train': preds_train,
        'predictions_test': preds_test,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'r2_train': r2_train,
        'mape': mape,
        'color': config['color']
    }
    
    print(f"   ‚úÖ MAE: {mae:.2f} | RMSE: {rmse:.2f} | R¬≤: {r2:.4f} | MAPE: {mape:.2f}%")

# =============================================================================
# üìä TABLEAU COMPARATIF
# =============================================================================

print("\n" + "="*70)
print("üìä TABLEAU COMPARATIF DES MOD√àLES")
print("="*70)

print(f"\n{'Mod√®le':<20} {'MAE':<10} {'RMSE':<10} {'R¬≤':<10} {'MAPE':<10} {'Overfitting'}")
print("-"*70)

for name, res in results.items():
    overfitting = res['r2_train'] - res['r2']
    overfit_status = "‚ö†Ô∏è Oui" if overfitting > 0.15 else "‚úÖ Non"
    
    print(f"{name:<20} {res['mae']:<10.2f} {res['rmse']:<10.2f} "
          f"{res['r2']:<10.4f} {res['mape']:<10.2f} {overfit_status}")

# Meilleur mod√®le
best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
best = results[best_model_name]

print("\n" + "="*70)
print(f"üèÜ MEILLEUR MOD√àLE: {best_model_name}")
print("="*70)
print(f"MAE  : ¬±{best['mae']:.2f} patients")
print(f"RMSE : ¬±{best['rmse']:.2f} patients")
print(f"R¬≤   : {best['r2']:.4f} ({best['r2']*100:.1f}% de variance expliqu√©e)")
print(f"MAPE : {best['mape']:.2f}%")

# Sauvegarder le nom du meilleur mod√®le
with open("meilleur_modele.txt", "w") as f:
    f.write(best_model_name)

# =============================================================================
# üìä VISUALISATIONS
# =============================================================================

print("\nüìä G√©n√©ration des graphiques...")

# GRAPHIQUE COMPARATIF
fig, axes = plt.subplots(2, 2, figsize=(16, 12))

# 1. Comparaison des m√©triques
ax1 = axes[0, 0]
x_pos = np.arange(len(results))
width = 0.25

r2s = [results[name]['r2'] for name in results.keys()]
maes = [results[name]['mae'] for name in results.keys()]
mapes = [results[name]['mape'] for name in results.keys()]

ax1.bar(x_pos - width, r2s, width, label='R¬≤', color='#3498DB', alpha=0.8)
ax1.bar(x_pos, [m/10 for m in maes], width, label='MAE/10', color='#E74C3C', alpha=0.8)
ax1.bar(x_pos + width, [m/100 for m in mapes], width, label='MAPE/100', color='#27AE60', alpha=0.8)

ax1.set_ylabel('Score (normalis√©)', fontsize=11)
ax1.set_title('üìä Comparaison des M√©triques', fontsize=12, fontweight='bold')
ax1.set_xticks(x_pos)
ax1.set_xticklabels(results.keys())
ax1.legend()
ax1.grid(True, alpha=0.3, axis='y')

# 2. Pr√©dictions vs R√©alit√© (tous les mod√®les)
ax2 = axes[0, 1]
ax2.plot(test['date'], test[target], label='R√©alit√©', 
         color='#2C3E50', linewidth=3, marker='o', markersize=5)

for name, res in results.items():
    ax2.plot(test['date'], res['predictions_test'], 
             label=f'{name} (R¬≤={res["r2"]:.3f})',
             linestyle='--', linewidth=2, alpha=0.7)

ax2.set_title('üéØ Pr√©dictions vs R√©alit√© (tous mod√®les)', fontsize=12, fontweight='bold')
ax2.set_ylabel('Admissions', fontsize=11)
ax2.legend(fontsize=9)
ax2.grid(True, alpha=0.3)
plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)

# 3. Scatter plot du meilleur mod√®le
ax3 = axes[1, 0]
ax3.scatter(test[target], best['predictions_test'], 
           alpha=0.6, color=best['color'], s=80, edgecolors='black')
min_val = min(test[target].min(), best['predictions_test'].min())
max_val = max(test[target].max(), best['predictions_test'].max())
ax3.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Pr√©diction parfaite')
ax3.set_xlabel('R√©alit√©', fontsize=11)
ax3.set_ylabel('Pr√©diction', fontsize=11)
ax3.set_title(f'üìà {best_model_name}: R√©alit√© vs Pr√©diction', fontsize=12, fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3)

# 4. R√©sidus du meilleur mod√®le
ax4 = axes[1, 1]
residuals = test[target].values - best['predictions_test']
colors = ['#27AE60' if r >= 0 else '#E74C3C' for r in residuals]
ax4.bar(range(len(residuals)), residuals, color=colors, alpha=0.7)
ax4.axhline(y=0, color='black', linestyle='-', linewidth=1.5)
ax4.axhline(y=best['mae'], color='orange', linestyle='--', linewidth=1.5, label=f'MAE: ¬±{best["mae"]:.2f}')
ax4.axhline(y=-best['mae'], color='orange', linestyle='--', linewidth=1.5)
ax4.set_title(f'üìâ {best_model_name}: Analyse des erreurs', fontsize=12, fontweight='bold')
ax4.set_ylabel('Erreur (Pr√©diction - R√©alit√©)', fontsize=11)
ax4.set_xlabel('Observation', fontsize=11)
ax4.legend()
ax4.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig("graphA_comparaison_modeles.png", dpi=150, bbox_inches='tight')
plt.close()

print("‚úÖ graphA_comparaison_modeles.png")

# =============================================================================
# üìÑ RAPPORT TEXTE
# =============================================================================

print("\nüìÑ G√©n√©ration du rapport...")

rapport = f"""
{'='*70}
RAPPORT DE COMPARAISON DES MOD√àLES DE MACHINE LEARNING
H√¥pital Piti√©-Salp√™tri√®re - Pr√©diction des Admissions
{'='*70}

1. MOD√àLES COMPAR√âS
{'='*70}

"""

for name, config in models.items():
    res = results[name]
    rapport += f"""
{name}:
  Description: {config['description']}
  MAE:  {res['mae']:.2f} patients
  RMSE: {res['rmse']:.2f} patients
  R¬≤:   {res['r2']:.4f} ({res['r2']*100:.1f}% de variance expliqu√©e)
  MAPE: {res['mape']:.2f}%
  
  Overfitting: R¬≤_train={res['r2_train']:.4f}, R¬≤_test={res['r2']:.4f}
               Diff√©rence: {res['r2_train'] - res['r2']:.4f}
               {'‚ö†Ô∏è Risque de surapprentissage' if (res['r2_train'] - res['r2']) > 0.15 else '‚úÖ Pas de surapprentissage'}
"""

rapport += f"""

2. CLASSEMENT
{'='*70}

"""

# Classement par R¬≤
sorted_models = sorted(results.items(), key=lambda x: x[1]['r2'], reverse=True)
for i, (name, res) in enumerate(sorted_models, 1):
    rapport += f"{i}. {name:<20} R¬≤ = {res['r2']:.4f}\n"

rapport += f"""

3. MOD√àLE S√âLECTIONN√â
{'='*70}

üèÜ {best_model_name}

Justification:
  - Meilleur R¬≤ ({best['r2']:.4f})
  - Erreur moyenne de ¬±{best['mae']:.2f} patients
  - MAPE de {best['mape']:.2f}% (tr√®s faible)
  
Interpr√©tation du R¬≤:
  Le mod√®le explique {best['r2']*100:.1f}% de la variance des admissions.
  Cela signifie que {best['r2']*100:.1f}% des variations d'admissions sont
  pr√©dictibles gr√¢ce aux features temporelles et historiques.

4. RECOMMANDATION
{'='*70}

Le mod√®le {best_model_name} est recommand√© pour la mise en production car:
  ‚úÖ Performance optimale (R¬≤ = {best['r2']:.4f})
  ‚úÖ Erreur acceptable (MAE = {best['mae']:.2f} patients)
  ‚úÖ Pas de surapprentissage significatif
  ‚úÖ G√©n√©ralise bien sur donn√©es de test

Ce mod√®le sera utilis√© pour les pr√©dictions √† 7 jours.

{'='*70}
Rapport g√©n√©r√© le {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
{'='*70}
"""

with open("rapport_comparaison_modeles.txt", "w", encoding='utf-8') as f:
    f.write(rapport)

print("‚úÖ rapport_comparaison_modeles.txt")

print("\n" + "="*70)
print("‚úÖ COMPARAISON TERMIN√âE")
print("="*70)
print(f"\nüèÜ Meilleur mod√®le: {best_model_name}")
print(f"üìÅ Fichiers g√©n√©r√©s:")
print(f"   - graphA_comparaison_modeles.png")
print(f"   - rapport_comparaison_modeles.txt")
print(f"   - meilleur_modele.txt")
print(f"\nüí° Utilisez '{best_model_name}' pour l'entra√Ænement final")